---
title: '산업공학특론I_9주차_다중회귀분석_실습'
author: 'Munwon Lim'
date: '5/1/2024'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(fig.width=9, fig.height=9)
```

<br>
<br>
<br>



## [데이터 분석]

(https://www.kaggle.com/datasets/rukenmissonnier/manufacturing-data-for-polynomial-regression?resource=download)

데이터 설명

다양한 공정 환경과 제품 품질 간의 관계를 탐색하기 위해 설계
공정 조건을 나타내는 변수와 제조된 항목의 품질 등급을 나타내는 변수를 모두 포함

* TemperatureC: 제조 공정 중 측정된 섭씨 온도
* PressurekPa: 제조 공정 중 가해진 압력을 킬로파스칼 (kPa) 단위로 측정
* TemperaturexPressure: 온도와 압력 사이의 상호 작용, 두 공정 변수의 결합된 영향을 고려
* MaterialFusionMetric: 온도의 제곱과 압력의 세제곱의 합으로 계산된 파생 메트릭 - 제조 공정 중 재료 융합 관련 측정값
* MaterialTransformationMetric: 온도의 세제곱에서 압력의 제곱을 뺀 것으로 계산된 다른 파생 메트릭 - 재료 변형 역학 관련 측정값
* Quality Rating: 생산된 항목의 전체 품질 등급으로, 최종 제품의 품질을 측정하는 지표

<br>
<br>
<br>

### 1. 데이터 탐색 (EDA) 및 전처리
```{r eda}

# 데이터 로드 및 요약
dat <- read.csv('산업공학특론I_9주차_실습 데이터.csv')
head(dat)

# 데이터 전처리
colnames(dat) <- gsub('[.]','',colnames(dat))
summary(dat)

# 학습, 테스트셋 분할
set.seed(0)
trainidx <- sample(1:nrow(dat), 0.8*nrow(dat))
train <- dat[trainidx,]
test <- dat[-trainidx,]

# 데이터 시각화
plot(train)

```

<br>

### 2. 상관분석
```{r correlation}
library(corrplot)

# 상관계수 테이블 생성
corr <- cor(train, method='pearson')

# 상관계수 테이블 시각화
col <- colorRampPalette(c('red','blue'))
corrplot(corr, method='color', col=col(200), addCoef.col = 'black', type='upper')

```

<br>

### 3. 다중회귀분석

```{r regression}

# 다중회귀모형 수립
# 1) CV 수행 X
reg <- lm(QualityRating~., data=train)
summary(reg)

# 2) CV 수행 O
library(caret)
train_cv <- trainControl(method = "cv", number = 10) 
reg_cv <- train(QualityRating~ ., data=train, method = "lm", 
               trControl = train_cv)

# 모델 수립 결과
summary(reg)
summary(reg_cv) #cv결과와 동일

```


<br>

### 4. 변수선택법

```{r variableselection}

# 변수선택법 시행
# 1) CV 수행 X
reg_step1 <- step(reg, direction='forward')
reg_step2 <- step(reg, direction='backward')
reg_step3 <- step(reg, direction='both')

# 2) CV 수행 O
reg_step1_cv <- train(QualityRating ~ ., data = train, method = 'glmStepAIC', 
                     trControl = train_cv, direction='forward', trace=F)
reg_step2_cv <- train(QualityRating ~ ., data = train, method = 'glmStepAIC', 
                     trControl = train_cv, direction='backward', trace=F)
reg_step3_cv <- train(QualityRating ~ ., data = train, method = 'glmStepAIC', 
                     trControl = train_cv, direction='both', trace=F)

# 모델 수립 결과
summary(reg_step1) #reg와 동일
summary(reg_step2)
summary(reg_step3) #reg_step2와 동일

summary(reg_step1_cv) 
summary(reg_step2_cv) #reg_step2와 동일 
summary(reg_step3_cv) #reg_step2와 동일 

reg_step <- reg_step2

```


<br>

### 5. 정규화 회귀분석

```{r regularization}
library(glmnet)

# 정규화 회귀모형 수립
regreg <- function(alpha, cv=F){
  x <- as.matrix(train[,-6]); y <- as.matrix(train[,6])
  if (cv){ 
    model <- cv.glmnet(x,y, alpha=alpha) 
    
    # lambda 값에 따른 오차 시각화
    plot(model)
    
  } else { 
    model <- glmnet(x,y, alpha=alpha) 
    
    # lambda값에 따른 변수 계수 시각화
    plot(model, xvar='lambda')
    legend('bottomright', legend=colnames(x), col=1:5, lty=1, cex=0.5)
  }
  return(model)
}

par(mfrow=c(2,3))

# 1) CV 수행 X
lasso <- regreg(1)
ridge <- regreg(0)
elastic <- regreg(0.5)

# 2) CV 수행 O
lasso_cv <- regreg(1,T)
ridge_cv <- regreg(0,T)
elastic_cv <- regreg(0.5,T)


# 모델 수립 결과
# 최적 lambda 값에 따른 계수 확인
coef(lasso_cv)
coef(ridge_cv)
coef(elastic_cv)

```

<br>

### 6. 모형 평가 

```{r evaluation}

# 적합결과 평가 (학습모형 대상, 정규화 회귀분석은 AIC 평가 불가능)
regeval <- function(regr){
  sumreg <- summary(regr)
  result <- tryCatch({
    c(sumreg$adj.r.squared, sumreg$sigma^2, AIC(regr))
  }, error = function(x){
    x <- train[,-6]; y <- train[,6]
    pred <- predict(reg, x)
    sse <- sum((pred - y)^2); ssr <- sum((pred - mean(y))^2); sst <- sse+ssr

    mse <- sse/(nrow(x) - length(reg$coef))
    rsq <- ssr/sst
    adjrsq <- 1- (nrow(x)-1)/(nrow(x) - length(reg$coef)) * (1- rsq)
    
    c(adjrsq, mse, NA)
  })
  names(result) <- c('adjRsq','MSE','AIC')
  print(round(result,4))
}

regeval(reg)
regeval(reg_step)
regeval(lasso_cv)
regeval(ridge_cv)
regeval(elastic_cv)



# 예측력 평가 (테스트셋 대상)
library(Metrics)

err <- function(model){
  newx <- test[,-ncol(test)]
  actual <- test[,ncol(test)]
  pred <- 
    tryCatch({ predict(model, newx)}, 
             error=function(x){ predict(model, as.matrix(newx))})
  err <- c(mae(actual,pred), mse(actual, pred), rmse(actual,pred))
  names(err) <- c('MAE','MSE','RMSE')
  print(err)
}

err(reg)
err(reg_step)
err(lasso_cv)
err(ridge_cv)
err(elastic_cv)

```
